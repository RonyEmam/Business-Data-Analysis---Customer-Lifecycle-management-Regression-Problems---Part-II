{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Copy of Homework_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYwLs5joJfJN"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\"><b></b>\n",
        "<h1><center> <font color='black'> Homework 02  </font></center></h1>\n",
        "<h2><center> <font color='black'> Regression & Regularization</font></center></h2>    \n",
        "<h2><center> <font color='black'> MTAT.03.319 - Business Data Analytics</font></center></h2>\n",
        "<h2><center> <font color='black'> University of Tartu - Spring 2021</font></center></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMAvgHx6JfJm"
      },
      "source": [
        "# Homework instructions\n",
        "\n",
        "- Please provide the names and student IDs of the team-members (Maximum 2 person) in the field \"Team mates\" below. If you are not working in a team please insert only your name and student ID. \n",
        "\n",
        "- The accepted submission formats are Colab links or .ipynb files. If you are submitting Colab links please make sure that the privacy settings for the file is public so we can access your code. \n",
        "\n",
        "- The submission will automatically close on <font color='red'>**21 March at 23:59**</font>, so please make sure to submit before the deadline. \n",
        "\n",
        "- ONLY one of the teammates should submit the homework. We will grade the homework and the marks and feedback is applied for both the team members. So please communicate with your team member about marks and feedback if you are submit the homework.\n",
        "\n",
        "- If a question is not clear, please ask us in Moodle ONLY. \n",
        "\n",
        "- After you have finished solving the Homework, please restart the Kernel and run all the cells to check if there is any persisting issues. \n",
        "\n",
        "- Plagiarism is <font color='red'>**PROHIBITED**</font>. Any form of plagiarism will be dealt according to the university policy (https://www.ut.ee/en/current-students/academic-fraud).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfgmDl7JJfJn"
      },
      "source": [
        "**<h2><font color='red'>Team mates:</font></h2>**\n",
        "\n",
        "\n",
        "**<font color='red'>Name: Mohga Emam </font>&emsp;   <font color='red'>Student ID: \tC09505 </font>**\n",
        "\n",
        "\n",
        "**<font color='red'>Name: Rewan Emam </font>&emsp;   <font color='red'>Student ID: \tC07851 </font>**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQFbVbtpJfJn"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "* In this homework you are going to apply supervised learning: Linear Regression method using Scikit-learn package; Scikit-learn (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy [https://en.wikipedia.org/wiki/Scikit-learn].\n",
        "\n",
        "### The homework is divided into four sections and the points are distributed as below:\n",
        "<pre>\n",
        "- Linear Regression    -> 2 points\n",
        "- PCA                  -> 2 points\n",
        "- Overfitting          -> 5 points\n",
        "_________________________________________\n",
        "Total                  -> 9 points\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1wszlIpJfJo"
      },
      "source": [
        "# 1. Regression \n",
        "## 1.1 Linear Regression (2 points)\n",
        "\n",
        "We are going to use the Prices dataset that contains 74 columns. Each column represents a feature of houses for sale. The ```SalePrice``` column  shows their prices. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qidamLnMJfJo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "50d2816b-b2d0-48f5-a94c-4369a5da10b7"
      },
      "source": [
        "# Recall the required libraries:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Plot the dataset:\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/RewanEmam/Regression-Regularization/main/Prices_Last_Updated.csv', sep= ',', index_col=0)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>Embarked_C (all)</th>\n",
              "      <th>Embarked_RL</th>\n",
              "      <th>Embarked_RM</th>\n",
              "      <th>Embarked_Pave</th>\n",
              "      <th>...</th>\n",
              "      <th>Embarked_Detchd</th>\n",
              "      <th>Embarked_Maj1</th>\n",
              "      <th>Embarked_Maj2</th>\n",
              "      <th>Embarked_Min1</th>\n",
              "      <th>Embarked_Min2</th>\n",
              "      <th>Embarked_Mod.1</th>\n",
              "      <th>Embarked_Sev.1</th>\n",
              "      <th>Embarked_Typ</th>\n",
              "      <th>Embarked_Ex.5</th>\n",
              "      <th>Embarked_Fa.6</th>\n",
              "      <th>Embarked_Gd.7</th>\n",
              "      <th>Embarked_TA.6</th>\n",
              "      <th>Embarked_Floor</th>\n",
              "      <th>Embarked_GasA</th>\n",
              "      <th>Embarked_GasW</th>\n",
              "      <th>Embarked_Grav</th>\n",
              "      <th>Embarked_OthW</th>\n",
              "      <th>Embarked_Wall</th>\n",
              "      <th>Embarked_Abnorml</th>\n",
              "      <th>Embarked_AdjLand</th>\n",
              "      <th>Embarked_Alloca</th>\n",
              "      <th>Embarked_Family</th>\n",
              "      <th>Embarked_Normal</th>\n",
              "      <th>Embarked_Partial</th>\n",
              "      <th>Embarked_Ex.6</th>\n",
              "      <th>Embarked_Fa.7</th>\n",
              "      <th>Embarked_Gd.8</th>\n",
              "      <th>Embarked_Po.4</th>\n",
              "      <th>Embarked_TA.7</th>\n",
              "      <th>Embarked_N.1</th>\n",
              "      <th>Embarked_Y.1</th>\n",
              "      <th>Embarked_COD</th>\n",
              "      <th>Embarked_CWD</th>\n",
              "      <th>Embarked_Con</th>\n",
              "      <th>Embarked_ConLD</th>\n",
              "      <th>Embarked_ConLI</th>\n",
              "      <th>Embarked_ConLw</th>\n",
              "      <th>Embarked_New</th>\n",
              "      <th>Embarked_Oth</th>\n",
              "      <th>Embarked_WD</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSSubClass</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>196.0</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>208500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>181500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>162.0</td>\n",
              "      <td>486</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>223500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>140000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>350.0</td>\n",
              "      <td>655</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>250000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 270 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            LotFrontage  LotArea  ...  Embarked_Oth  Embarked_WD\n",
              "MSSubClass                        ...                           \n",
              "60                 65.0     8450  ...             0            1\n",
              "20                 80.0     9600  ...             0            1\n",
              "60                 68.0    11250  ...             0            1\n",
              "70                 60.0     9550  ...             0            1\n",
              "60                 84.0    14260  ...             0            1\n",
              "\n",
              "[5 rows x 270 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5dxc_JaJfJq"
      },
      "source": [
        "The column names are self-explanatory which indicates features of each house."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt1Kln3rJfJq"
      },
      "source": [
        "**1.1.1. The target label is```SalePrice``` which means, later we will predict the sale-price based on the given features (columns). But for regression task, it is important to ensure that the data is not skewed. In order to do that, please plot the distribution of ```SalePrice``` column and explain what do you see. (0.2 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJbRJKE8JfJq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "4516377d-977b-4aef-f740-c4db0dc3f892"
      },
      "source": [
        "## The original data is skewed\n",
        "\n",
        "\n",
        "# Plot the histogram\n",
        "plt.hist(df.SalePrice, bins = 80, color='pink', ec='black', alpha=0.5)\n",
        "\n",
        "# Creating some customizations\n",
        "plt.xlabel('SalePrice')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Visulaizing the SalePrice')\n",
        "plt.grid(True)\n",
        "plt.xticks(fontsize = 10) \n",
        "plt.yticks(fontsize = 10) \n",
        "\n",
        "# Visulaize the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UthxdZLyJfJq"
      },
      "source": [
        "**<font color='red'>Answer: Based on the original data that we have, the data is skew. and it repesents the properties of houses based on different factors such as the tear built, the type of properties, the sale conditions, etc. We can say that the SalePrice is the dependent factor \"Y\" and it depends on several independent factors. In order to fix the skew issue, I have used \"Log transform\" method and then I tested and the result is: 0.01213350. It is pretty satisfying but I tried different method which is \"Square Root Transform\" method and it didn't work as I expected. Finally, I have tried \"Box-Cox Transform\" method, and it turned out that the final method is the best method of all three methods. As the skew dropped to 0.008652.</font>** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl0qQwwdJfJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9dbbce-4980-4565-b4f5-e97029b224bb"
      },
      "source": [
        "# Log Transform method:\n",
        "df_log = np.log(df['SalePrice'])\n",
        "df_log.skew()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12133506220520406"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "atDPtCICzTGS",
        "outputId": "358b2d45-93a3-4e02-ecdb-446ec6ce9c0c"
      },
      "source": [
        "# Visualize the SalePrice after I have applied Log Transform method:\n",
        "plt.hist(df_log, bins = 90, color='pink', ec='black', alpha=0.5)\n",
        "\n",
        "# Creating some customizations\n",
        "plt.xlabel('SalePrice')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Visulaizing the SalePrice')\n",
        "plt.grid(True)\n",
        "plt.xticks(fontsize = 15) \n",
        "plt.yticks(fontsize = 15) \n",
        "\n",
        "# Visulaize the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssv8zfThzYFn",
        "outputId": "178aca5d-6a24-4a54-a8c2-19f14b50eb18"
      },
      "source": [
        "# Box-Cox Transform method:\n",
        "df_boxcox = stats.boxcox(df['SalePrice'])[0]\n",
        "pd.Series(df_boxcox).skew()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.008652893640830005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "EzFjj3gCzYN_",
        "outputId": "49304308-4a5a-493e-f2ff-77203e466095"
      },
      "source": [
        "# Visualize the SalePrice after I have applied Box-Cox Transform method:\n",
        "plt.hist(df_boxcox, bins = 90, color='pink', ec='black', alpha=0.5)\n",
        "\n",
        "# Creating some customizations\n",
        "plt.xlabel('SalePrice')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Visulaizing the SalePrice')\n",
        "plt.grid(True)\n",
        "plt.xticks(fontsize = 15) \n",
        "plt.yticks(fontsize = 15) \n",
        "\n",
        "# Visulaize the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCEjKtlJJfJr"
      },
      "source": [
        "So, the data seems to be skewed which has to be fixed otherwise it may lead to erronous result. \n",
        "Apart from that, look closely, some columns are not numerical. For those, you have to convert them to numerical value or represent them in a way so that the algorithm can understand the data. One of such way is called, one hot encoding. Along with that, the algorithm cannot deal with NaN or Infinite values. So please address all of these in the preprocessing section. \n",
        "\n",
        "- Preprocess for skewed data\n",
        "- Apply one-hot encoding to categorical data types\n",
        "- Replace negative infinite values with 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1s3u1LLJfJr"
      },
      "source": [
        "**1.1.2. After preprocessing the skewed data, plot ```SalePrice``` column distribution again. (0.05 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A59X1K5fJfJs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "bfb674a8-e38e-4261-f69f-8e0679ba1ff2"
      },
      "source": [
        "# Add the new column:\n",
        "df['SalesPrice'] = df_boxcox\n",
        "\n",
        "# Visualize the SalePrice after I have applied Box-Cox Transform method:\n",
        "plt.hist(df['SalesPrice'], bins = 90, color='pink', ec='black', alpha=0.5)\n",
        "\n",
        "# Creating some customizations\n",
        "plt.xlabel('SalesPrice')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Visulaizing the SalePrice')\n",
        "plt.grid(True)\n",
        "plt.xticks(fontsize = 15) \n",
        "plt.yticks(fontsize = 15) \n",
        "\n",
        "# Visulaize the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQPBZ0QWJfJs"
      },
      "source": [
        "**1.1.3. Calculate the correlation between price and each feature. Which are the top 3 features that have the highest correlation with  price? Is the correlation positive or negative? Explain what happens with the price when each of those 3 features change (consider only one feature at a time) and others are kept constant. (0.25 point)** \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8h1X01iNKAt",
        "outputId": "834d48f9-044b-4fd8-bff2-30ddf8ba08d9"
      },
      "source": [
        "# Import all the required datasets:\n",
        "from sklearn.preprocessing import MinMaxScaler # preprocessing\n",
        "from sklearn.preprocessing import PolynomialFeatures # preprocessing\n",
        "from sklearn.preprocessing import scale # preprocessing\n",
        "from sklearn.feature_selection import RFE # preprocessing\n",
        "\n",
        "# rescale the features\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# apply scaler() to all the numeric columns \n",
        "numeric_vars = ['LotArea', 'YearBuilt', 'SalePrice', 'OverallCond', 'GrLivArea', 'OverallQual', 'LotFrontage']\n",
        "df[numeric_vars] = scaler.fit_transform(df[numeric_vars])\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            LotFrontage   LotArea  ...  Embarked_WD  SalesPrice\n",
            "MSSubClass                         ...                         \n",
            "60             0.150685  0.033420  ...            1    7.932610\n",
            "20             0.202055  0.038795  ...            1    7.878263\n",
            "60             0.160959  0.046507  ...            1    7.959618\n",
            "70             0.133562  0.038561  ...            1    7.774955\n",
            "60             0.215753  0.060576  ...            1    8.002875\n",
            "...                 ...       ...  ...          ...         ...\n",
            "60             0.140411  0.030929  ...            1    7.863875\n",
            "20             0.219178  0.055505  ...            1    7.935404\n",
            "70             0.154110  0.036187  ...            1    8.027382\n",
            "20             0.160959  0.039342  ...            1    7.781006\n",
            "20             0.184932  0.040370  ...            1    7.795887\n",
            "\n",
            "[1460 rows x 271 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "VuMMjBoG0jTg",
        "outputId": "39707599-fbf0-4579-c7a7-20ab795951b1"
      },
      "source": [
        "# Compute the correlation between the price & Yearbuilt\n",
        "\n",
        "SalPrice_SalCond = list(['SalePrice', 'YearBuilt'])\n",
        "df[SalPrice_SalCond].corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>YearBuilt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SalePrice</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.522897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YearBuilt</th>\n",
              "      <td>0.522897</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           SalePrice  YearBuilt\n",
              "SalePrice   1.000000   0.522897\n",
              "YearBuilt   0.522897   1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "aIlClr4r0mSl",
        "outputId": "14c8b442-5751-4acf-b8bd-113fc0fcc1d5"
      },
      "source": [
        "# Compute the correlation between the price & OverallCond\n",
        "\n",
        "SalPrice_OverallCond = list(['SalePrice', 'OverallCond'])\n",
        "df[SalPrice_OverallCond].corr() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>OverallCond</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SalePrice</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.077856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OverallCond</th>\n",
              "      <td>-0.077856</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             SalePrice  OverallCond\n",
              "SalePrice     1.000000    -0.077856\n",
              "OverallCond  -0.077856     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "xCeUc7Lr0mWH",
        "outputId": "f740439d-ba40-4af0-e758-861433ecf77d"
      },
      "source": [
        "# Compute the correlation between the price & GrLivArea\n",
        "\n",
        "SalPrice_GrLivArea = list(['SalePrice', 'GrLivArea'])\n",
        "df[SalPrice_GrLivArea].corr() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>GrLivArea</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SalePrice</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.708624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GrLivArea</th>\n",
              "      <td>0.708624</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           SalePrice  GrLivArea\n",
              "SalePrice   1.000000   0.708624\n",
              "GrLivArea   0.708624   1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "odwYkCs60mbm",
        "outputId": "626cd197-3325-4c26-9717-b91362c5a6ba"
      },
      "source": [
        "# Compute the correlation between the price & OverallQual\n",
        "\n",
        "SalPrice_OverallQual = list(['SalePrice', 'OverallQual'])\n",
        "df[SalPrice_OverallQual].corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>OverallQual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SalePrice</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.790982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OverallQual</th>\n",
              "      <td>0.790982</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             SalePrice  OverallQual\n",
              "SalePrice     1.000000     0.790982\n",
              "OverallQual   0.790982     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "_s6kC9Il0mek",
        "outputId": "3c2ffb55-7056-43f5-efa5-08ffce69f83e"
      },
      "source": [
        "# Compute the correlation between the price & LotFrontage\n",
        "\n",
        "SalPrice_LotFrontage = list(['SalePrice', 'LotFrontage'])\n",
        "df[SalPrice_LotFrontage].corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>LotFrontage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SalePrice</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.351799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotFrontage</th>\n",
              "      <td>0.351799</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             SalePrice  LotFrontage\n",
              "SalePrice     1.000000     0.351799\n",
              "LotFrontage   0.351799     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "kYk64kMk0mhe",
        "outputId": "79733a69-ea6a-46ad-9ac0-5b2626c99d94"
      },
      "source": [
        "# Compute the correlation between the price & LotArea\n",
        "\n",
        "SalPrice_LotArea = list(['SalePrice', 'LotArea'])\n",
        "df[SalPrice_LotArea].corr()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>LotArea</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SalePrice</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.263843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotArea</th>\n",
              "      <td>0.263843</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           SalePrice   LotArea\n",
              "SalePrice   1.000000  0.263843\n",
              "LotArea     0.263843  1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "R7TCbD8UFRif",
        "outputId": "e03fedf7-06c4-4764-c245-4fe4db1741f5"
      },
      "source": [
        "corr = {'col_names' : df.loc[:, df.columns != 'SalePrice'].corrwith(df['SalePrice']).keys().tolist(), 'corr_vals': df.loc[:, df.columns != 'SalePrice'].corrwith(df['SalePrice']).values.tolist()}\n",
        "corrs = pd.DataFrame(corr)  \n",
        "corrs = corrs.sort_values(by=['corr_vals'],ascending=False).reset_index(drop=True)\n",
        "corrs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_names</th>\n",
              "      <th>corr_vals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OverallQual</td>\n",
              "      <td>0.790982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GrLivArea</td>\n",
              "      <td>0.708624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GarageCars</td>\n",
              "      <td>0.640409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GarageArea</td>\n",
              "      <td>0.623431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TotalBsmtSF</td>\n",
              "      <td>0.613581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>Embarked_None</td>\n",
              "      <td>-0.374468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>Embarked_Unf.2</td>\n",
              "      <td>-0.410608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>Embarked_TA.2</td>\n",
              "      <td>-0.452394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>Embarked_TA.6</td>\n",
              "      <td>-0.519298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>Embarked_TA</td>\n",
              "      <td>-0.589044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>269 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          col_names  corr_vals\n",
              "0       OverallQual   0.790982\n",
              "1         GrLivArea   0.708624\n",
              "2        GarageCars   0.640409\n",
              "3        GarageArea   0.623431\n",
              "4       TotalBsmtSF   0.613581\n",
              "..              ...        ...\n",
              "264   Embarked_None  -0.374468\n",
              "265  Embarked_Unf.2  -0.410608\n",
              "266   Embarked_TA.2  -0.452394\n",
              "267   Embarked_TA.6  -0.519298\n",
              "268     Embarked_TA  -0.589044\n",
              "\n",
              "[269 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLYyFSd-JfJt"
      },
      "source": [
        "<font color='red'> **Answer: the top 3 features that have the highest correlation with price are: OverallQual, GrLivArea, and GarageCars. The correlation is positive. Since There's a positive correlation with the price column and the top 3 column so if any values fluctuated the price column will be affected as well.**\n",
        "</font>\n",
        "\n",
        "*   <font color='red'>Regarding the OverallQual column: If the values in the OverallQual decreased then the values in the price column will decrease as well which makes sense in the daily life because the higher the house quality the higher the price. The lower the house quality the lower the price.</font>\n",
        "*   <font color='red'>Regarding the GrLivArea: If the values in the GrLivArea increased the price column values will increase, If it decreased the price value will decrease.</font>\n",
        "*   <font color='red'>Regarding the GarageCars: If the values in the GarageCars column increased the price column values will increase, If it decreased the price value will decrease.</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qQzbp4RJfJt"
      },
      "source": [
        "**1.1.4.  Now you have to build a regression model that would be trained on training data and later predict the price on test data. You are free to select features on which you want train the model. The dataset has missing values, so please apply the following methods for dealing with the missing data in the features of your choice:**\n",
        "\n",
        "a) mean imputation\n",
        "\n",
        "b) median imputation\n",
        "\n",
        "c) mode imputation\n",
        "\n",
        "d) dropping missing values\n",
        "\n",
        "**Split dataset into the training (80% of the all rows) and test ( 20% of all rows) set, you can use train_test_split function from scikit-learn. While splitting, set the parameter random_state equal to 2, this will reproduce similar split during grading.**\n",
        "\n",
        "**For each of the case report MAE, RMSE and R<sup>2</sup>. Which method works better ?(1.50 points)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt559gopHyU4"
      },
      "source": [
        "# I choose to apply mean imputation\n",
        "df.columns[df.isna().any()].tolist() # ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
        "df['LotFrontage'].fillna(np.mean(df['LotFrontage']), inplace=True)\n",
        "df['MasVnrArea'].fillna(np.mean(df['MasVnrArea']), inplace=True)\n",
        "df['GarageYrBlt'].fillna(np.mean(df['GarageYrBlt']), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3xAdkWxPMn0"
      },
      "source": [
        "# I choose the columns with the highest correlation to the SalePrice\n",
        "selected_col = df[corrs.col_names.head(10).tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCaoOjKWJfJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59e2ed46-624b-4cc3-a456-70b6839f0eef"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "methods = ['mean imputation', 'median imputation', 'mode imputation', 'dropping missing values']\n",
        "#Store the result in the following variables\n",
        "MAE = []\n",
        "RMSE = []\n",
        "R2 = [] \n",
        "\n",
        "# Split the dataset into train set & test set:\n",
        "X = selected_col\n",
        "y = df['SalePrice']\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=2)\n",
        "\n",
        "regressor = LinearRegression()\n",
        "\n",
        "#TODO: train the regression model\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "y_predicted = regressor.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_predicted)\n",
        "rmse = (np.sqrt(mean_squared_error(y_test, y_predicted)))\n",
        "r2 = r2_score(y_test, y_predicted)\n",
        "\n",
        "    \n",
        "print(\"MAE: \" + str(mae) + \"  RMSE: \" + str(rmse) + \"  R2: \" + str(r2))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 21946.21355087014  RMSE: 30185.553842971687  R2: 0.8624084638882776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di6eU4kRJfJt"
      },
      "source": [
        "<font color='red'> **Answer: The method that works best is the R2 in my opinion and that's because mae and rmse are doing bad job in finding the correct error. I choose the columns that has the highest correlation with the SalePrice column.**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4mCTiasJfJu"
      },
      "source": [
        "**Please store the best MAE, RMSE, r2_best score in the following variables. We will use these variable to compare ```1.2.7```**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD8eDSFNJfJv"
      },
      "source": [
        "mae_best = mae    #best MAE\n",
        "rmse_best = rmse  #best RMSE\n",
        "r2_best = r2      #best R2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgkUo5YBJfJv"
      },
      "source": [
        "# 1.2 Principal Component Analysis (PCA) (2 points)\n",
        "Our model performs quite good. But there is always room to make it better and simpler. By simpler, we mean the reducing the dimensionality of the dataset so that we can have a simpler linear regression model. <br> <br>If you noticed after one-hot encoding, we have 270 features (columns) but all these features do not hold the same level of information. For example, the first feature may hold 50% of the information required to make the linear regression acheive the performance we already had; the last, (feature number 270) may contribute to only 0.0000001% to the total output. Hence, adding this last variable (actually there could be more) to our linear regression model (read equation) will only increase the complexity of the model; space, time and computational complexity. Therefore, it is wise and desirable to make the model simpler yet performing the best (better). \n",
        "<br> <br>\n",
        "One such way to reduce the dimensionality of the dataset is known as Pricipal Component Analysis. Using this method, we can find out which features contribute the most in our model, therefore, we can wisely select how many we need. We will perform, PCA in this section of the homework. <br><br>\n",
        "\n",
        "*There is another powerful method for dimensionality reduction, named t-SNE. We will use t-sne in future homework. <br><br>*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm5DmYT3JfJv"
      },
      "source": [
        "**1.2.1. From ```1.1.4``` keep the best method to deal with missing values and apply PCA to reduce the number of features. (0.5point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soV-exvTLuJ9",
        "outputId": "941f5b6b-07ea-4d4d-bee2-999f0fcb6680"
      },
      "source": [
        "df.isnull().any().sum() # make sure there's no null or missing values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy7hzDhHJfJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df8ed312-23d7-402c-b941-5d9c79a2bfdf"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "X = selected_col\n",
        "y = df['SalePrice']\n",
        "#TODO: initialize pca, pass, whiten=True, svd_solver='randomized', random_state=0\n",
        "pca = PCA(whiten=True, svd_solver='randomized', random_state=0)\n",
        "\n",
        "#TODO: fit pca\n",
        "pca.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=None, random_state=0,\n",
              "    svd_solver='randomized', tol=0.0, whiten=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2XRbpPsNPoV",
        "outputId": "48f587af-9d05-4683-e37a-867eaba4828b"
      },
      "source": [
        "np.var(pca.explained_variance_ratio_[:5])*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.769932092405191"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-w3klggJfJw"
      },
      "source": [
        "**1.2.2. What percentage of the variance is explained by the first five components? (0.10 point)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQEVP0WjJfJw"
      },
      "source": [
        "<font color='red'> **Answer: The variance percentages is 6.769932092405191% I calculated it by calculating the variance of the first 5 componenets and multiplaying it by 100 to get the percentage.**</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ELb09LJfJw"
      },
      "source": [
        "It would be helpful if we could see all of the variance against the number of components, so a plot would give us a better understanding of the situation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3FzebW5JfJ2"
      },
      "source": [
        "**1.2.3. Please plot the result of PCA you built in ```1.2.1```<br>\n",
        "X-axis=Number of Components, Y-axis=Total explained variance and explain the result.(0.5 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irp6UKBbJfJ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "6559700f-1a4f-4417-e98c-61e2bb596b44"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,7))\n",
        "lw=2\n",
        "plt.plot(pca.explained_variance_ratio_,pca.explained_variance_, color='k', lw=lw)\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Total explained variance')\n",
        "    \n",
        "plt.xlim(0, 300)\n",
        "plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "\n",
        "plt.axhline(0.9, c='c')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKEwADKDOjPg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHnlCo-5JfJ3"
      },
      "source": [
        "<font color='red'> **Answer:**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_4PB8XRJfJ4"
      },
      "source": [
        "**1.2.5. Again, from ```1.1.4``` keep the best method to deal with missing values and use PCA to reduce the number of features. But you can use only the number of features that are significant in ```1.1.3```, in this case you have to choose an optimum n_component value based on the PCA plot. Otherwise, you can select all of the features and pass the n_components=37. In all cases, keep random_state for PCA equal to 0. (0.20 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5V5J9lkJfJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac53918-e0e0-4c9b-bbd4-4299fd3d625d"
      },
      "source": [
        "pca = PCA(n_components= 37,whiten=True, svd_solver='randomized', random_state=0)\n",
        "pca.get_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseEstimator.get_params of PCA(copy=True, iterated_power='auto', n_components=37, random_state=0,\n",
              "    svd_solver='randomized', tol=0.0, whiten=True)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4FJY3P_s10q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ii2fvRuJfJ4"
      },
      "source": [
        "**1.2.6. Use the new components derived from PCA to predict the house pricing. Keep the ratio of test and train set to 20/80 and the random_state equal to 0. Report MAE, RMSE and R<sup>2</sup> (0.60 point)** <br>\n",
        "*Hint: Now your training data is different. Please use pca.transform(X) function to create your new training dataset. But make sure you have the fitted pca from ```1.2.5```*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO8i5zgiJfJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b5ae50-20c3-4fab-ee72-e90ba8cbe950"
      },
      "source": [
        "# pca_X = pca.transform(X)\n",
        "\n",
        "\n",
        "methods = ['mean imputation', 'median imputation', 'mode imputation', 'dropping missing values']\n",
        "MAE = []\n",
        "RMSE = []\n",
        "R2 = []\n",
        "    \n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
        "\n",
        "regressor = LinearRegression()\n",
        "\n",
        "#TODO: train the regression model\n",
        "regressor.fit(X_train_pca, y_train_pca)\n",
        "\n",
        "y_predicted_pca = regressor.predict(X_test_pca)\n",
        "\n",
        "mae_pca = mean_absolute_error(y_test_pca, y_predicted_pca)\n",
        "rmse_pca = (np.sqrt(mean_squared_error(y_test_pca, y_predicted_pca)))\n",
        "r2_pca = r2_score(y_test_pca, y_predicted_pca)\n",
        "\n",
        "    \n",
        "print(\"MAE: \" + str(mae_pca) + \"  RMSE: \" + str(rmse_pca) + \"  R2: \" + str(r2_pca))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 24772.97620515129  RMSE: 48904.66493710956  R2: 0.6536753238084512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ8DEaLyJfJ4"
      },
      "source": [
        "**1.2.7 The following cell would calculate the difference between pre-PCA and post-PCA. Please explain the situation based on the differences. (0.1 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLFLGYHnJfJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086740c6-f5c6-40ec-fb94-ecf59303c67a"
      },
      "source": [
        "print(\"MAE difference after PCA: \", mae_best-mae_pca)\n",
        "print(\"RMSE difference after PCA: \", rmse_best-rmse_pca)\n",
        "print(\"R2 difference after PCA: \", r2_best-r2_pca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE difference after PCA:  -2826.762654281152\n",
            "RMSE difference after PCA:  -18719.111094137876\n",
            "R2 difference after PCA:  0.20873314007982646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTZCW4GEJfJ5"
      },
      "source": [
        "<font color='red'> **Answer: I think that the mean absolute error and mean squared error and the r2 scrore have decresead when we use PCA because PCA calculated them automatically so It's more accurate and what PCA does is dimentionality reduction so I think that helped in decreasing the erorr percentage a lot.**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVj81M_uJfJ5"
      },
      "source": [
        "## 1.3 Overfitting (5 points)\n",
        "\n",
        "Now our model is comparatively better than the earlier models. It is less complex yet performs the almost the same. Let's dive a little deeper into the model now. In this section, we will check if the model is overfitting. The concept of overfitting has already been delivered in the lectures. However, if you are interesed in honing it up, please take a look here or anywhere you understand better: https://datascience.foundation/sciencewhitepaper/underfitting-and-overfitting-in-machine-learning\n",
        "<br>\n",
        "But, unfortunately it is difficult to know if a model is overfitting or underfitting. One way to know more about model's performance is cross-validation. Cross-validation is also used in the hyperparameter searching to find the best performing model in a given scenario.  \n",
        "We have a few techniques to prevent overfitting and we will focus on \n",
        "- 1.3.1 Cross-validation \n",
        "    - K-Fold cross-validation: Most common (we would apply this one to see the performance of the Linear regression model)\n",
        "    - Leave One Out (LOO): Takes each row as the validation set for once, and trains the model on the rest n-1 rows. Thus, it trains n number of models.\n",
        "\n",
        "    - Leave P-Out (LPO): Creates possible splits after leaving p samples out. For n rows, there would be (nCp) possibile train-test splits.\n",
        "    - (For classification problems) Stratified K-Fold: Ensures relative class proportion is preserved in each train and validation fold. Important when the class label is imbalanced (e.g. 95% label: 1; 5% label: 0).\n",
        "    \n",
        "    *The last three techniques will be discussed in detail in the 7th Lecture.* <br><br>\n",
        "    \n",
        "- 1.3.2 Regularization \n",
        "    - L1 (Lasso)    \n",
        "    - L2 (Ridge)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgnrzErbJfJ5"
      },
      "source": [
        "**1.3.0. Now we have to check if the trained regression model in ```1.1.4``` is overfitting. Please use R<sup>2</sup> value on train and test result to determine the overfitting. Please explain the result from the perspective of the dataset and the value(0.2 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U9AhTxCJfJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7bbd66e-0964-4c49-b557-01f92151399e"
      },
      "source": [
        "X = df.loc[:, df.columns != 'SalePrice']\n",
        "y = df['SalePrice']\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.2, random_state=2)\n",
        "\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)\n",
        "y_predicted = regressor.predict(X_test)\n",
        "r2 = r2_score(y_test, y_predicted)\n",
        "print(\"rscore: \",r2)\n",
        "print(\"MAE: \",mean_absolute_error(y_test, y_predicted) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rscore:  -558325.7358365107\n",
            "MAE:  7107647.680854301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aejhzWfUJfJ6"
      },
      "source": [
        "<font color='red'> **Answer: I think there's an underfitting in the data but this may be due to something in the data preprocessing phase or something in my model.**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la1JX3IhJfJ6"
      },
      "source": [
        "**1.3.1 Please apply K-fold=10 fold closs validation on the training dataset of ```1.1.4``` Keep random_state=1, shuffle=True, while performing cross validation, make sure that return_train_score=True.(0.5 point)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cZsA7alJfJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ea132a-1784-4a8d-9c74-7ea6a20bb07d"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "cv = KFold(n_splits = 10, shuffle = True, random_state = 1)\n",
        "#TODO: create model\n",
        "lm = LinearRegression()\n",
        "\n",
        "#TODO: evaluate model using R^2, and MSE as evaluation metrics\n",
        "#While setting MSE metrics, make sure you pass the right keyword \n",
        "scores = cross_validate(lm, X, y, cv=3,scoring=('r2', 'neg_mean_squared_error'),return_train_score=True)\n",
        "scores \n",
        "\n",
        "# report performance\n",
        "print('R^2: %.3f (%.3f)' % (mean(scores['test_r2']), std(scores['test_r2'])))\n",
        "print('MSE: %.3f (%.3f)' % (mean(scores['test_neg_mean_squared_error']), std(scores['test_neg_mean_squared_error'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2: 0.822 (0.058)\n",
            "MSE: -1120470950.926 (348190877.273)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TALQSL6JJfJ6"
      },
      "source": [
        "**1.3.1.2. Please plot the training and test R<sup>2</sup> value where X-axis=number of folds, Y-axis=R<sup>2</sup> value. Explain the plot, if the model shows overfitting or not.(0.3 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6AxRDbsJfJ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "20896199-2d13-4436-97a6-ad426e802f31"
      },
      "source": [
        "plt.figure(figsize=(16,6))\n",
        "#TODO: plot the trendlines ['test_r2'] train_r2\n",
        "plt.plot([1,2,3], scores['test_r2']);\n",
        "plt.plot([1,2,3], scores['train_r2']);\n",
        "plt.xlabel('number of folds');\n",
        "plt.ylabel('r^2 value');\n",
        "plt.title(\"the training and test R2 value\");\n",
        "plt.legend(['test r2', 'train r2'], loc='upper left');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fn1Lem85jf-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq62bO4LJfJ6"
      },
      "source": [
        "<font color='red'> **Answer: I think that the model is overfitting because it does well on the trainging data and not so well on the test data. we have trained the model so much to the point that it doesn't LEARN rather than memorize the data so when we test it on the test data it applies the memorization not the learning and that's why it's overfitting.**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRU2r7W0JfJ7"
      },
      "source": [
        "**1.3.2  Please apply L1 (Lasso) regularization with variable alpha parameters and report the corresponding alpha value and R<sup>2</sup> value. Use the training split from ```1.1.4``` (1.5 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JBLdIUk6JfJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c3384c-2c33-44c4-c0a9-db0706b1900d"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "\n",
        "\n",
        "cross_val_scores_lasso = [] \n",
        "  \n",
        "# List to maintain the different values of alpha \n",
        "alpha = [] \n",
        "\n",
        "\n",
        "\n",
        "# Loop to for different alpha value \n",
        "for i in range(1, 9):\n",
        "    #TODO: formulate the lasso model where alpha=i * 0.0001\n",
        "    lassoModel = Lasso(alpha = i * 0.0001,)  \n",
        "    #TODO: fit the lasso model on whole X, y\n",
        "    #TODO: perform 10 fold cross validation and store the result in score variable\n",
        "    lassoModel.fit(X_train, y_train) \n",
        "    scores = cross_val_score(lassoModel, X, y, cv = 10) \n",
        "    avg_cross_val_score = mean(scores)*100\n",
        "    cross_val_scores_lasso.append(avg_cross_val_score) \n",
        "    alpha.append(i * 0.0001)  \n",
        "  \n",
        "  \n",
        "# Loop to print the different values of cross-validation scores \n",
        "for i in range(0, len(alpha)): \n",
        "    print(str(alpha[i])+' : '+str(cross_val_scores_lasso[i])) \n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 218557811700.4933, tolerance: 726904594.7462255\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 295285940878.124, tolerance: 852398977.1246127\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 288871873786.2016, tolerance: 827439703.8697119\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 291539076148.03564, tolerance: 829042909.2707292\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 247932958834.3991, tolerance: 820538852.086489\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272210807613.63034, tolerance: 785203388.8728524\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 246676714442.56012, tolerance: 834664899.9449157\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 286992719071.8107, tolerance: 844788544.228661\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 290085848276.68463, tolerance: 846871145.510494\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 270465848535.80716, tolerance: 801728446.7415172\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 289135138380.14844, tolerance: 843859692.9252497\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 218555889801.3082, tolerance: 726904594.7462255\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 295285302443.178, tolerance: 852398977.1246127\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 288871291310.6802, tolerance: 827439703.8697119\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 291535855551.6724, tolerance: 829042909.2707292\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 247932042640.83096, tolerance: 820538852.086489\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272210279816.6802, tolerance: 785203388.8728524\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 246676299385.21896, tolerance: 834664899.9449157\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 286989821224.6031, tolerance: 844788544.228661\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 290085251026.00464, tolerance: 846871145.510494\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 270464729632.8468, tolerance: 801728446.7415172\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 289134441233.728, tolerance: 843859692.9252497\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 218553967284.63217, tolerance: 726904594.7462255\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 295284663680.62665, tolerance: 852398977.1246127\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 288870708587.6935, tolerance: 827439703.8697119\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 291532633858.6901, tolerance: 829042909.2707292\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 247931125853.03012, tolerance: 820538852.086489\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272209751603.09622, tolerance: 785203388.8728524\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 246675884107.4515, tolerance: 834664899.9449157\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 286986922292.0775, tolerance: 844788544.228661\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 290084653491.02484, tolerance: 846871145.510494\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 270463609857.60083, tolerance: 801728446.7415172\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 289133743783.1376, tolerance: 843859692.9252497\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 218552044093.6172, tolerance: 726904594.7462255\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 295284024589.0851, tolerance: 852398977.1246127\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 288870125584.0915, tolerance: 827439703.8697119\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 291529411024.3783, tolerance: 829042909.2707292\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 247930208470.63687, tolerance: 820538852.086489\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272209223182.003, tolerance: 785203388.8728524\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 246675468526.3433, tolerance: 834664899.9449157\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 286984022281.61365, tolerance: 844788544.228661\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 290084055668.9802, tolerance: 846871145.510494\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 270462489737.26108, tolerance: 801728446.7415172\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 289133046016.07996, tolerance: 843859692.9252497\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 218550120237.26935, tolerance: 726904594.7462255\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 295283385168.9567, tolerance: 852398977.1246127\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 288869542296.90515, tolerance: 827439703.8697119\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 291526187052.4479, tolerance: 829042909.2707292\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 247929290492.0746, tolerance: 820538852.086489\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272208691706.98697, tolerance: 785203388.8728524\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 246675052641.94272, tolerance: 834664899.9449157\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 286981121190.1951, tolerance: 844788544.228661\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 290083457559.82275, tolerance: 846871145.510494\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 270461368725.54584, tolerance: 801728446.7415172\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 289132347933.63226, tolerance: 843859692.9252497\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 218548195715.74484, tolerance: 726904594.7462255\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 295282744751.63983, tolerance: 852398977.1246127\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 288868958725.43744, tolerance: 827439703.8697119\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 291522961943.04333, tolerance: 829042909.2707292\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 247928371916.82968, tolerance: 820538852.086489\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272208165476.2472, tolerance: 785203388.8728524\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 246674636452.47632, tolerance: 834664899.9449157\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 286978219015.35004, tolerance: 844788544.228661\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 290082859163.61584, tolerance: 846871145.510494\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 270460247006.13785, tolerance: 801728446.7415172\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 289131649528.47125, tolerance: 843859692.9252497\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 218546270529.02972, tolerance: 726904594.7462255\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 295282105454.3148, tolerance: 852398977.1246127\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 288868374869.436, tolerance: 827439703.8697119\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 291519735695.9969, tolerance: 829042909.2707292\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 247927453945.8573, tolerance: 820538852.086489\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272207635498.1186, tolerance: 785203388.8728524\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 246674219966.57074, tolerance: 834664899.9449157\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 286975315754.3622, tolerance: 844788544.228661\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 290082260480.0699, tolerance: 846871145.510494\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 270459210905.20737, tolerance: 801728446.7415172\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 289130950814.15045, tolerance: 843859692.9252497\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 218544344677.02847, tolerance: 726904594.7462255\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 295281458458.26117, tolerance: 852398977.1246127\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 288867790728.75684, tolerance: 827439703.8697119\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 291516508310.8886, tolerance: 829042909.2707292\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 247926532989.9418, tolerance: 820538852.086489\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 272207106762.29416, tolerance: 785203388.8728524\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 246673803635.56717, tolerance: 834664899.9449157\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 286972411404.052, tolerance: 844788544.228661\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 290081661509.27856, tolerance: 846871145.510494\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 270458003032.90384, tolerance: 801728446.7415172\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.0001 : 82.658544441893\n",
            "0.0002 : 82.65858409181608\n",
            "0.00030000000000000003 : 82.65862341843138\n",
            "0.0004 : 82.65866340329279\n",
            "0.0005 : 82.65870370101695\n",
            "0.0006000000000000001 : 82.6587439641418\n",
            "0.0007 : 82.65878482023616\n",
            "0.0008 : 82.65882432777548\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 289130251785.58984, tolerance: 843859692.9252497\n",
            "  positive)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bfFzmDfJfJ7"
      },
      "source": [
        "**1.3.3. Take the best alpha value from ```1.3.2``` and use it to train a new lasso model and report the  R<sup>2</sup> value on test set. Use the train test split from ```1.1.4```. (0.5 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26ebQVQ6JfJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4677bbca-43b7-47f9-a4e8-e6e2c8197082"
      },
      "source": [
        "# Building and fitting the Lasso Regression Model \n",
        "from sklearn.model_selection import train_test_split\n",
        "lassoModelBest = Lasso(alpha = 0.0008,)\n",
        "#TODO: Fit the model again \n",
        "lassoModelBest.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating the Lasso Regression model \n",
        "print(lassoModelBest.score(X_test, y_test)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8105075790702908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 218544344677.02847, tolerance: 726904594.7462255\n",
            "  positive)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNhJ6cwkJfJ7"
      },
      "source": [
        "**1.3.4.  Please apply L2 (Ridge) regularization with variable alpha parameters and report the corresponding alpha value and R<sup>2</sup> value. Use the training split from ```1.1.4``` (1.5 point)**\n",
        "\n",
        "N.B. The $alpha$ here in the ridge regularization is the same as $lambda$ you saw in the lecture. We did not initiate the variable with $lambda$ because $lambda$ is a reserved keyword in python which is used to create small anonymous functions. A $lambda$ function can take any number of arguments, but can only have one expression.\n",
        "You can read more about it here: https://www.w3schools.com/python/ref_keyword_lambda.asp#:~:text=The%20lambda%20keyword%20is%20used,and%20the%20result%20is%20returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQXWz0z4JfJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3695391-9bca-46f4-ac6d-aa6312e913fa"
      },
      "source": [
        "cross_val_scores_ridge = [] \n",
        "  \n",
        "# List to maintain the different values of alpha \n",
        "alpha = [] \n",
        "\n",
        "\n",
        "\n",
        "# Loop to for different alpha value \n",
        "for i in range(1, 9): \n",
        "    #TODO: formulate the ridge model where alpha=i * 0.0001\n",
        "    ridgeModel = Ridge(alpha = i * 0.0001)\n",
        "    #TODO: fit the ridge model on whole X, y\n",
        "    #TODO: perform 10 fold cross validation and store the result in score variable\n",
        "    ridgeModel.fit(X_train, y_train) \n",
        "    scores = cross_val_score(ridgeModel, X, y, cv = 10) \n",
        "    avg_cross_val_score = mean(scores)*100\n",
        "    \n",
        "    cross_val_scores_ridge.append(avg_cross_val_score) \n",
        "    alpha.append(i * 0.0001) \n",
        "  \n",
        "# Loop to print the different values of cross-validation scores \n",
        "for i in range(0, len(alpha)): \n",
        "    print(str(alpha[i])+' : '+str(cross_val_scores_ridge[i])) \n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0001 : 82.01137476598058\n",
            "0.0002 : 82.01283818605987\n",
            "0.00030000000000000003 : 82.01430012855961\n",
            "0.0004 : 82.01576059593442\n",
            "0.0005 : 82.01721959065097\n",
            "0.0006000000000000001 : 82.01867711517228\n",
            "0.0007 : 82.02013317193128\n",
            "0.0008 : 82.02158776339272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3k6yZXNJfJ8"
      },
      "source": [
        "**1.3.5. Take the best alpha value from ```1.3.4``` and use it to train a new ridge model and report the  R<sup>2</sup> value on test set. Use the train test split from ```1.1.4```. (0.5 point)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB_FtNHeJfJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee01f338-2b4e-49f2-ea4e-6700bc1d1360"
      },
      "source": [
        "# Building and fitting the Ridge Regression Model 0.0008\n",
        "from sklearn.model_selection import train_test_split\n",
        "ridgeModelBest = Ridge(alpha = 0.0008)\n",
        "\n",
        "#TODO: Fit the model again \n",
        "ridgeModelBest.fit(X_train, y_train)\n",
        "# Evaluating the ridge Regression model \n",
        "print(ridgeModelBest.score(X_test, y_test)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8084684079441264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-5hoCclJfJ8"
      },
      "source": [
        "## How long did it take you to solve the homework?\n",
        "\n",
        "* Please answer as precisely as you can. It does not affect your points or grade in any way. It is okay, if it took 0.5 hours or 24 hours. The collected information will be used to improve future homeworks.\n",
        "\n",
        "\n",
        "\n",
        "**<font color='red'>(please change X in the next cell into your estimate)</font>**\n",
        "\n",
        "<font color='red'> **Answer:**</font> X hours\n",
        "\n",
        "## What is the level of difficulty for this homework?\n",
        "you can put only number between $0:10$ ($0:$ easy, $10:$ difficult)\n",
        "\n",
        "<font color='red'> **Answer:**</font>"
      ]
    }
  ]
}